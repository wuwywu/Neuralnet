{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep Residual Learning for Image Recognition (ResNet)\n",
    "This is a PyTorch implementation of the paper Deep Residual Learning for Image Recognition. \n",
    "\n",
    "paper : https://papers.labml.ai/paper/ecbad378ae7311eb9864394904658322"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear projections for shortcut connection\n",
    "当x与f的维度不同时，就不能使用恒等映射，而是应该使用线性投射而匹配维度"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ShortcutProjection(nn.Module):\n",
    "    def __init__(self, in_channels: int, out_channels: int, stride: int):\n",
    "        super().__init__()\n",
    "        self.conv = nn.Conv2d(in_channels, out_channels, kernel_size=1, stride=stride)\n",
    "        self.bn = nn.BatchNorm2d(out_channels)\n",
    "\n",
    "    def forward(self,  x: torch.Tensor):\n",
    "        return self.bn(self.conv(x))\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# torch.nn.Identity --> 占位用的，输入什么输出什么\n",
    "恒等函数"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 残差块 residual mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResidualBlock(nn.Module):\n",
    "    def __init__(self, in_channels: int, out_channels: int, stride: int):\n",
    "        super().__init__()\n",
    "        self.res = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, out_channels, kernel_size=3, stride=stride, padding=1),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(out_channels, out_channels, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(out_channels)\n",
    "        )\n",
    "        if stride != 1 or in_channels != out_channels:\n",
    "            self.shortcut = ShortcutProjection(in_channels, out_channels, stride)\n",
    "        else:\n",
    "            self.shortcut = nn.Identity()\n",
    "        self.act = nn.ReLU()\n",
    "\n",
    "    def forward(self, x: torch.Tensor):\n",
    "        shortcut = self.shortcut(x)\n",
    "        x = self.res(x)\n",
    "\n",
    "        return self.act(x+shortcut)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bottleneck Residual Block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BottleneckResidualBlock(nn.Module):\n",
    "    def __init__(self, in_channels: int, bottleneck_channels: int, out_channels: int, stride: int):\n",
    "        super().__init__()\n",
    "        self.res = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, bottleneck_channels, kernel_size=1, stride=1),\n",
    "            nn.BatchNorm2d(bottleneck_channels),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(bottleneck_channels, bottleneck_channels, kernel_size=3, stride=stride, padding=1),\n",
    "            nn.BatchNorm2d(bottleneck_channels),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(bottleneck_channels, out_channels, kernel_size=1, stride=1),\n",
    "            nn.BatchNorm2d(out_channels)\n",
    "        )\n",
    "        if stride != 1 or in_channels != out_channels:\n",
    "            self.shortcut = ShortcutProjection(in_channels, out_channels, stride)\n",
    "        else:\n",
    "            self.shortcut = nn.Identity()\n",
    "        self.act = nn.ReLU()\n",
    "\n",
    "        \n",
    "    def forward(self, x: torch.Tensor):\n",
    "        shortcut = self.shortcut(x)\n",
    "        x = self.res(x)\n",
    "\n",
    "        return self.act(x+shortcut)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ResNet Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResNetBase(nn.Module):\n",
    "    def __init__(self, n_blocks, n_channels, bottlenecks=None,\n",
    "                img_channels: int = 3, first_kernel_size: int = 7):\n",
    "        super().__init__()\n",
    "        assert len(n_blocks) == len(n_channels) # 模块和通道数不一致\n",
    "        assert bottlenecks is None or len(bottlenecks) == len(n_channels)\n",
    "        self.conv = nn.Conv2d(img_channels, n_channels[0],\n",
    "                             kernel_size=first_kernel_size, stride=2, padding=first_kernel_size//2)\n",
    "        self.bn = nn.BatchNorm2d(n_channels[0])\n",
    "        blocks = []\n",
    "        prev_channels = n_channels[0]\n",
    "        for i, channels in enumerate(n_channels):\n",
    "            stride = 2 if len(blocks) == 0 else 1\n",
    "            if bottlenecks is None:\n",
    "                blocks.append(ResidualBlock(prev_channels, channels, stride=stride))\n",
    "            else:\n",
    "                blocks.append(BottleneckResidualBlock(prev_channels, bottlenecks[i], channels,\n",
    "                                                      stride=stride))\n",
    "            prev_channels = channels\n",
    "\n",
    "            for _ in range(n_blocks[i] - 1):              \n",
    "                if bottlenecks is None:\n",
    "                    blocks.append(ResidualBlock(channels, channels, stride=1))\n",
    "                else:\n",
    "                    blocks.append(BottleneckResidualBlock(channels, bottlenecks[i], channels, stride=1))\n",
    "\n",
    "        self.blocks = nn.Sequential(*blocks)\n",
    "    \n",
    "    def forward(self, x: torch.Tensor):\n",
    "        x = self.bn(self.conv(x))\n",
    "        x = self.blocks(x)\n",
    "        x = x.view(x.shape[0], x.shape[1], -1)\n",
    "\n",
    "        return x.mean(dim=-1)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
